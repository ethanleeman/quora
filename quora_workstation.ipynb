{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import unidecode\n",
    "from sklearn.metrics import jaccard_score, log_loss\n",
    "import re\n",
    "import pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Leeman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "train = train.dropna()\n",
    "test = test.fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has\",\n",
    "\"I'd\": \"I had\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shiver\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "print(spell('shiwer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f2267776a695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\[math\\].*\\[\\/math\\]\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/py37/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "re.sub(\"\\[math\\].*\\[\\/math\\]\" , ' ',train['question1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block takes a few minutes\n",
    "\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean(text):\n",
    "    #remove html/things in boxes\n",
    "    text = re.sub(\"\\[math\\].*\\[\\/math\\]\" , ' ', text)\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = str.lower(text)\n",
    "    text = re.sub(\"-\", \" \", text)\n",
    "    text = re.sub(\"\\(.*\\)\", \" \", text)\n",
    "    text = expand_contractions(text)\n",
    "    text = re.sub(\"[\\?\\#\\'\\\",.!:]+\", \"\", text)\n",
    "    for s in sym_spell.lookup_compound(text, max_edit_distance=2):\n",
    "        text = s.term\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if not w in stop_words] \n",
    "  \n",
    "    return tokens\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#train['question1_cleaned'] = train['question1'].apply(clean)\n",
    "#train['question2_cleaned'] = train['question2'].apply(clean)\n",
    "#test['question1_cleaned'] = test['question1'].apply(clean)\n",
    "#test['question2_cleaned'] = test['question2'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for s in sym_spell.lookup_compound(\"paper mker\", max_edit_distance=2):\n",
    "    print(type(s.term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SymSpell',\n",
       " 'Verbosity',\n",
       " '__author__',\n",
       " '__author_email__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__description__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__license__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__title__',\n",
       " '__version__',\n",
       " 'editdistance',\n",
       " 'helpers',\n",
       " 'symspellpy']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(symspellpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "members, 1, 226656153\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "# lookup suggestions for single-word input strings\n",
    "input_term = \"memebers\"  # misspelling of \"members\"\n",
    "# max edit distance per lookup\n",
    "# (max_edit_distance_lookup <= max_dictionary_edit_distance)\n",
    "suggestions = sym_spell.lookup(input_term, Verbosity.CLOSEST,\n",
    "                               max_edit_distance=2)\n",
    "# display suggestion term, term frequency, and edit distance\n",
    "for suggestion in suggestions:\n",
    "    print(suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                                              [step, step, guide, invest, share, market, india]\n",
      "1                                                                                                     [story, kohinoor, diamond]\n",
      "2                                                                            [increase, speed, internet, connection, using, van]\n",
      "3                                                                                                      [mentally, lonely, solve]\n",
      "4                                                         [one, dissolve, water, quickly, sugar, salt, methane, carbon, dioxide]\n",
      "5                                                                       [astrology, capricorn, sun, cap, moon, cap, rising, say]\n",
      "6                                                                                                                    [buy, iago]\n",
      "7                                                                                                              [good, geologist]\n",
      "8                                                                                                                 [use, instead]\n",
      "9                                                                                   [motorola, hack, charter, motorola, dcx3400]\n",
      "10                                                                     [method, find, separation, slit, using, fresnel, baptism]\n",
      "11                                                                                                [read, find, youtube, comment]\n",
      "12                                                                                                   [make, physic, easy, learn]\n",
      "13                                                                                             [first, sexual, experience, like]\n",
      "14                                       [law, change, status, student, visa, green, card, u, compare, immigration, law, canada]\n",
      "15                                               [would, trump, presidency, mean, current, international, master, student, visa]\n",
      "16                                                                                                          [manipulation, mean]\n",
      "17                                                                                             [girl, want, friend, guy, reject]\n",
      "18                                                             [many, quota, user, posting, question, readily, answered, google]\n",
      "19                                                                            [best, digital, marketing, institution, bangalore]\n",
      "20                                                                                                         [rocket, look, white]\n",
      "21                                                                                                   [causing, someone, jealous]\n",
      "22                                                                                                        [question, ask, quota]\n",
      "23                                                                                                                        [much]\n",
      "24                                                                                      [mean, every, time, look, clock, number]\n",
      "25                                                                              [tip, making, job, interview, process, medicine]\n",
      "26                                                                                                            [web, application]\n",
      "27                                                                                     [society, place, much, importance, sport]\n",
      "28                                                                                              [best, way, make, money, online]\n",
      "29                                                                                                         [prepare, final, law]\n",
      "30                                                                                             [one, thing, would, like, better]\n",
      "31                                                                            [special, care, someone, nose, get, stuffy, night]\n",
      "32                                                                           [game, throne, villain, would, likely, give, mercy]\n",
      "33                                        [united, state, government, still, blacklist, united, state, citizen, political, view]\n",
      "34                                                                                                [best, travel, website, spain]\n",
      "35                                                                                  [people, think, obama, try, take, gun, away]\n",
      "36                                                                 [year, old, improve, skill, become, entrepreneur, next, year]\n",
      "37                                                                 [girlfriend, asks, boyfriend, choose, make, want, one, reply]\n",
      "38                                                                                                                [prepare, ups]\n",
      "39                                                                                 [stall, speed, aka, wing, fully, swept, back]\n",
      "40                                                                                                                 [slav, squat]\n",
      "41                                                                                       [expect, cognizant, confirmation, mail]\n",
      "42                                                                                            [make, 50000, month, day, trading]\n",
      "43                                                                                          [good, kid, rebel, worth, long, run]\n",
      "44                                                                    [university, rex, ord, recruit, new, grad, major, looking]\n",
      "45                                                                               [quickest, way, increase, inst, gram, follower]\n",
      "46                                                                        [darth, vader, fought, darth, maul, star, war, legend]\n",
      "47                                        [stage, breaking, couple, mean, happens, breaking, emotionally, whether, male, female]\n",
      "48                                                                                          [example, product, make, crude, oil]\n",
      "49                                                                                                                [make, friend]\n",
      "50                                                                             [career, launcher, good, rib, grade, preparation]\n",
      "51                                                                                             [blu, ray, play, regular, player]\n",
      "52                                                                                                                 [always, sad]\n",
      "53                                                                                         [best, memorable, thing, ever, eaten]\n",
      "54                                                                                                   [get, affect, tax, officer]\n",
      "55                                                                                                         [difficult, get, sri]\n",
      "56                                                                                                              [israel, friend]\n",
      "57                                                                                                      [good, rap, song, dance]\n",
      "58                                [suddenly, logged, email, remember, email, password, realized, recovery, email, longer, alive]\n",
      "59                                                                                                    [best, way, learn, french]\n",
      "60                                                                 [download, content, kick, as, torrent, without, registration]\n",
      "61                                                                                       [normal, dark, ring, around, iris, eye]\n",
      "62                                                                      [new, harry, potter, book, harry, potter, cursed, child]\n",
      "63                                                                                                      [always, get, depressed]\n",
      "64                                                                                    [find, european, family, office, database]\n",
      "65                                                                       [java, programming, learn, java, programming, language]\n",
      "66                                                                                                      [best, book, ever, made]\n",
      "67                                                                                    [ever, store, energy, produced, lightning]\n",
      "68                                                                                                [review, performance, testing]\n",
      "69                                                         [cost, much, privacy, germany, come, else, lost, gain, much, privacy]\n",
      "70                                                                                                              [type, immunity]\n",
      "71                                                                                         [narcissistic, personality, disorder]\n",
      "72                                                                                                    [speak, english, fluently]\n",
      "73                          [helpful, quick, book, auto, data, recovery, support, phone, number, recover, corrupted, data, file]\n",
      "74                                                                                        [richest, gambler, time, reach, level]\n",
      "75                                           [fire, bullet, backward, aircraft, going, faster, bullet, bullet, going, backwards]\n",
      "76                                                                                                     [prevent, breast, cancer]\n",
      "77                                                                                          [log, email, account, friend, phone]\n",
      "78                                                                                                       [make, money, internet]\n",
      "79                                                                                                               [purpose, life]\n",
      "80                              [bop, government, strip, muslim, christian, indian, citizenship, put, boat, like, rowing, burma]\n",
      "81                                                                [right, etiquette, wishing, jehovah, witness, happy, birthday]\n",
      "82                                     [someone, want, open, commercial, pm, radio, station, city, india, much, cost, procedure]\n",
      "83                                                                                                       [swiss, despise, asian]\n",
      "84                                                                             [high, salary, income, job, field, biotechnology]\n",
      "85                                                                                                      [increase, height, also]\n",
      "86                                                 [major, effect, cambodia, earthquake, effect, compare, kamchatka, earthquake]\n",
      "87                                                                                             [difference, sincerity, fairness]\n",
      "88                                                                                                   [best, gaming, laptop, ask]\n",
      "89                                                                                [review, next, warrior, proving, ground, part]\n",
      "90                                                                                        [best, reference, book, physic, class]\n",
      "91                                              [national, institute, technology, kurdish, extra, social, life, nick, surat, al]\n",
      "92                                                                                              [best, romantic, movie, english]\n",
      "93                                                                                                            [cause, nightmare]\n",
      "94                                                                                           [abstract, expressionism, painting]\n",
      "95                                                                                                          [cd, printing, work]\n",
      "96                                                                                  [like, attend, cal, tech, jeremy, earnhardt]\n",
      "97                                                                                                    [harry, become, hor, crux]\n",
      "98    [best, associate, product, manager, program, someone, early, join, learn, product, management, rewarding, career, company]\n",
      "99                                                                                                 [number, skype, always, busy]\n",
      "Name: question1, dtype: object\n",
      "1.1560859680175781\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "print(train.head(100)['question1'].map(clean))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.639119444444445"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train) + len(test))/100/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question2_cleaned'] = train['question2'].apply(clean)\n",
    "test['question1_cleaned'] = test['question1'].apply(clean)\n",
    "test['question2_cleaned'] = test['question2'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_cleaned.csv')\n",
    "test.to_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(row):\n",
    "    s1 = set(row['question1_cleaned'])\n",
    "    s2 = set(row['question2_cleaned'])\n",
    "    u = set(s1 | s2)\n",
    "    i = set(s1 & s2)\n",
    "    if len(u) > 0:\n",
    "        return len(i)/len(u)\n",
    "    return 0\n",
    "train['jaccard'] = train.apply(jaccard,axis=1)\n",
    "test['jaccard'] = test.apply(jaccard,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Compute ROC curve and ROC area for each class\n",
    "y = np.array(train['is_duplicate'])\n",
    "scores = np.array(train['jaccard'])\n",
    "fpr, tpr, thresholds = roc_curve(y, scores, pos_label=1)\n",
    "roc_auc = roc_auc_score(y, scores)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "y = np.array(train['is_duplicate'])\n",
    "x = np.array(train['jaccard']).reshape(-1,1)\n",
    "my_model = LogisticRegression(random_state=0,fit_intercept=True).fit(x, y)\n",
    "y_pred = my_model.predict_proba(x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(test['jaccard']).reshape(-1,1)\n",
    "test['is_duplicate'] = my_model.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['test_id','is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()\n",
    "submission.to_csv('my_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Word2Vec - take sums and take cosine similarity\n",
    "import gensim\n",
    "train = pd.read_csv('train_cleaned.csv')\n",
    "test = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./../models/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(row):\n",
    "    s1 = []\n",
    "    s2 = []\n",
    "    for w in row['question1_cleaned']:\n",
    "        if model.__contains__(w):\n",
    "            s1.append(w)\n",
    "    for w in row['question2_cleaned']:\n",
    "        if model.__contains__(w):\n",
    "            s2.append(w)\n",
    "    \n",
    "    \n",
    "    if len(s1) > 0 and len(s2) > 0:\n",
    "        return model.n_similarity(s1,s2)\n",
    "    return 0          \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['google_w2v_similarity'] = train.apply(similarity,axis=1)\n",
    "test['google_w2v_similarity'] = test.apply(similarity,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['google_w2v_similarity'] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train['is_duplicate'])\n",
    "scores = np.array(train['google_w2v_similarity'])\n",
    "fpr, tpr, thresholds = roc_curve(y, scores, pos_label=1)\n",
    "roc_auc = roc_auc_score(y, scores)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "y = np.array(train['is_duplicate'])\n",
    "x = np.array(train[['google_w2v_similarity']])\n",
    "my_model = LogisticRegression(random_state=0,fit_intercept=True).fit(x, y)\n",
    "y_pred = my_model.predict_proba(x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(test['google_w2v_similarity']).reshape(-1,1)\n",
    "test['is_duplicate'] = my_model.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.correlate(train['google_w2v_similarity'],train['jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
